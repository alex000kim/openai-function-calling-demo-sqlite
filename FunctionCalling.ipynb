{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with OpenAI's Function Calling\n",
    "\n",
    "This notebook demonstrates how to use [Function Calling](https://platform.openai.com/docs/guides/function-calling) functionality with the OpenAI API.\n",
    "\n",
    "In this demo, we'll use the Northwind database to convert natural language queries into SQL.\n",
    "\n",
    "There will be two function calling examples:\n",
    "\n",
    "1. A simple one-step function call to convert a natural language query into SQL, where we'll put the database schema into the system prompt and them use function calling to convert a natural language query into SQL.\n",
    "2. A two-step function call first gets the schema of the database and then converts a natural language query into SQL.\n",
    "\n",
    "At the end, we'll compare the two approaches and do a quick-and-dirty evaluation of the results using a hand-curated list of questions and their expected SQL queries in [`eval_questions.csv`](eval_questions.csv).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "\n",
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions to call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Categories': ['CategoryID', 'CategoryName', 'Description', 'Picture'],\n",
       " 'sqlite_sequence': ['name', 'seq'],\n",
       " 'CustomerCustomerDemo': ['CustomerID', 'CustomerTypeID'],\n",
       " 'CustomerDemographics': ['CustomerTypeID', 'CustomerDesc'],\n",
       " 'Customers': ['CustomerID',\n",
       "  'CompanyName',\n",
       "  'ContactName',\n",
       "  'ContactTitle',\n",
       "  'Address',\n",
       "  'City',\n",
       "  'Region',\n",
       "  'PostalCode',\n",
       "  'Country',\n",
       "  'Phone',\n",
       "  'Fax'],\n",
       " 'Employees': ['EmployeeID',\n",
       "  'LastName',\n",
       "  'FirstName',\n",
       "  'Title',\n",
       "  'TitleOfCourtesy',\n",
       "  'BirthDate',\n",
       "  'HireDate',\n",
       "  'Address',\n",
       "  'City',\n",
       "  'Region',\n",
       "  'PostalCode',\n",
       "  'Country',\n",
       "  'HomePhone',\n",
       "  'Extension',\n",
       "  'Photo',\n",
       "  'Notes',\n",
       "  'ReportsTo',\n",
       "  'PhotoPath'],\n",
       " 'EmployeeTerritories': ['EmployeeID', 'TerritoryID'],\n",
       " 'Order Details': ['OrderID',\n",
       "  'ProductID',\n",
       "  'UnitPrice',\n",
       "  'Quantity',\n",
       "  'Discount'],\n",
       " 'Orders': ['OrderID',\n",
       "  'CustomerID',\n",
       "  'EmployeeID',\n",
       "  'OrderDate',\n",
       "  'RequiredDate',\n",
       "  'ShippedDate',\n",
       "  'ShipVia',\n",
       "  'Freight',\n",
       "  'ShipName',\n",
       "  'ShipAddress',\n",
       "  'ShipCity',\n",
       "  'ShipRegion',\n",
       "  'ShipPostalCode',\n",
       "  'ShipCountry'],\n",
       " 'Products': ['ProductID',\n",
       "  'ProductName',\n",
       "  'SupplierID',\n",
       "  'CategoryID',\n",
       "  'QuantityPerUnit',\n",
       "  'UnitPrice',\n",
       "  'UnitsInStock',\n",
       "  'UnitsOnOrder',\n",
       "  'ReorderLevel',\n",
       "  'Discontinued'],\n",
       " 'Regions': ['RegionID', 'RegionDescription'],\n",
       " 'Shippers': ['ShipperID', 'CompanyName', 'Phone'],\n",
       " 'Suppliers': ['SupplierID',\n",
       "  'CompanyName',\n",
       "  'ContactName',\n",
       "  'ContactTitle',\n",
       "  'Address',\n",
       "  'City',\n",
       "  'Region',\n",
       "  'PostalCode',\n",
       "  'Country',\n",
       "  'Phone',\n",
       "  'Fax',\n",
       "  'HomePage'],\n",
       " 'Territories': ['TerritoryID', 'TerritoryDescription', 'RegionID']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get database schema\n",
    "def get_schema(db_path=\"northwind.db\"):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    schema = {}\n",
    "    for table in tables:\n",
    "        table_name = table[0]\n",
    "        cursor.execute(f\"PRAGMA table_info('{table_name}')\")\n",
    "        columns = cursor.fetchall()\n",
    "        schema[table_name] = [column[1] for column in columns]\n",
    "    return schema\n",
    "\n",
    "\n",
    "get_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from SQLite database given a query\n",
    "def read_data(query, db_path=\"northwind.db\"):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ground truth result\n",
    "\n",
    "We'll compare the LLM-generated results with this ground truth result `df_true` later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C么te de Blaye</td>\n",
       "      <td>53274482.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Th眉ringer Rostbratwurst</td>\n",
       "      <td>24630836.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mishi Kobe Niku</td>\n",
       "      <td>19424638.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sir Rodney's Marmalade</td>\n",
       "      <td>16654879.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carnarvon Tigers</td>\n",
       "      <td>12607487.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ProductName      Revenue\n",
       "0            C么te de Blaye  53274482.70\n",
       "1  Th眉ringer Rostbratwurst  24630836.96\n",
       "2          Mishi Kobe Niku  19424638.00\n",
       "3   Sir Rodney's Marmalade  16654879.80\n",
       "4         Carnarvon Tigers  12607487.50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example SQL query that answers the question: \"What is the total revenue for each product in the database?\"\n",
    "\n",
    "sample_query = \"\"\" \n",
    "SELECT\n",
    "    p.ProductName,\n",
    "    SUM(od.Quantity * od.UnitPrice) AS Revenue\n",
    "FROM  \n",
    "    Products p\n",
    "JOIN    \n",
    "    \"Order Details\" od\n",
    "ON\n",
    "    p.ProductID = od.ProductID\n",
    "GROUP BY\n",
    "    p.ProductName\n",
    "ORDER BY\n",
    "    Revenue DESC;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df_true = read_data(sample_query)\n",
    "df_true.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One function call\n",
    "\n",
    "Here we are doing the following:\n",
    "\n",
    "- Placing the database schema in the system prompt `SYSTEM_PROMPT_v1`.\n",
    "- Providing the user's question and the definition of the `read_data` function in the `tools` parameter to OpenAI Chat Completion API.\n",
    "- Calling the `read_data` function with the SQL query generated by the LLM\n",
    "- Finaly, we are returning both the SQL query and the result of the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_v1 = f\"\"\"\n",
    "            The user will ask a question about the database with the following schema:\n",
    "            ###\n",
    "            {str(get_schema())}\n",
    "            ###\n",
    "            Provide a SQL query answering the question.  \n",
    "            Avoid ambiguous column names.\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "def get_result_v1(user_question, system_prompt=SYSTEM_PROMPT_v1):\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "            \"content\": system_prompt},\n",
    "        {\"role\": \"user\",\n",
    "            \"content\": user_question}\n",
    "    ]\n",
    "    functions = [\n",
    "        # function to read data from the database\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"read_data\",\n",
    "                \"description\": \"Get pandas dataframe from SQLite database given a query\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"SQL query to execute\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\"]\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        temperature=0.0,  # for reproducibility\n",
    "        tools=functions,\n",
    "        messages=messages\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    messages.append(response_message)\n",
    "    tool_call = response_message.tool_calls[0]\n",
    "    function_name = tool_call.function.name\n",
    "    if function_name == \"read_data\":\n",
    "        # get the query from the tool call\n",
    "        sql_query = json.loads(tool_call.function.arguments)['query']\n",
    "        df = read_data(sql_query)\n",
    "        return sql_query, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two function calls\n",
    "\n",
    "Here's how this approach is different from the one-step function call:\n",
    "\n",
    "- `SYSTEM_PROMPT_v2` is a static string that does _not_ contain the database schema.\n",
    "- Both `get_schema` and `read_data` functions are passed in the `tools` parameter.\n",
    "- We make **two** API calls: one to get the schema and another to convert the natural language query into SQL.\n",
    "- We still return both the SQL query and the result of the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_v2 = \"\"\"\n",
    "        The user will ask a question about the database. \n",
    "        First, get the schema of the database. \n",
    "        Then, provide a SQL query answering the question.       \n",
    "        Avoid ambiguous column names.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "def get_result_v2(user_question, system_prompt=SYSTEM_PROMPT_v2):\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": system_prompt},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": user_question}\n",
    "    ]\n",
    "    functions = [\n",
    "        # function to get schema of the database\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_schema\",\n",
    "                \"description\": \"Get the schema of the SQLite database\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {},\n",
    "                    \"required\": []\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        # function to read data from the database\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"read_data\",\n",
    "                \"description\": \"Get pandas dataframe from SQLite database given a query\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"SQL query to execute\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\"]\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        temperature=0.0,\n",
    "        tools=functions,\n",
    "        messages=messages\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    messages.append(response_message)\n",
    "    tool_call = response_message.tool_calls[0]\n",
    "    function_name = tool_call.function.name\n",
    "    if function_name == \"get_schema\":\n",
    "        schema = get_schema()\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": str(schema),\n",
    "            }\n",
    "        )\n",
    "        second_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            temperature=0.0,\n",
    "            tools=functions,\n",
    "            messages=messages,\n",
    "        )\n",
    "\n",
    "        response_message = second_response.choices[0].message\n",
    "        messages.append(response_message)\n",
    "        tool_call = response_message.tool_calls[0]\n",
    "        function_name = tool_call.function.name\n",
    "        if function_name == \"read_data\":\n",
    "            # get the query from the tool call\n",
    "            sql_query = json.loads(tool_call.function.arguments)['query']\n",
    "            df = read_data(sql_query)\n",
    "            return sql_query, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's run some test queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One function call `get_result_v1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT p.ProductName, SUM(od.UnitPrice * od.Quantity * (1 - od.Discount)) AS TotalRevenue FROM Products p JOIN 'Order Details' od ON p.ProductID = od.ProductID GROUP BY p.ProductName ORDER BY TotalRevenue DESC;\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductName</th>\n",
       "      <th>TotalRevenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C么te de Blaye</td>\n",
       "      <td>5.326590e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Th眉ringer Rostbratwurst</td>\n",
       "      <td>2.462347e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mishi Kobe Niku</td>\n",
       "      <td>1.942304e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sir Rodney's Marmalade</td>\n",
       "      <td>1.665381e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carnarvon Tigers</td>\n",
       "      <td>1.260467e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ProductName  TotalRevenue\n",
       "0            C么te de Blaye  5.326590e+07\n",
       "1  Th眉ringer Rostbratwurst  2.462347e+07\n",
       "2          Mishi Kobe Niku  1.942304e+07\n",
       "3   Sir Rodney's Marmalade  1.665381e+07\n",
       "4         Carnarvon Tigers  1.260467e+07"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "What is the total revenue for each product in the database? \n",
    "Return a table with the product name and total revenue columns. \n",
    "Sort by total revenue in descending order.\n",
    "\"\"\"\n",
    "sql_query_v1, df_v1 = get_result_v1(question)\n",
    "print(sql_query_v1)\n",
    "df_v1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the generated SQL query, for some reason, contains `(1 - od.Discount)` despite the questions not mentioning any discounts.\n",
    "\n",
    "That's LLMs being LLMs! し\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the dataframes are the same\n",
    "\n",
    "# We convert the dataframes to numpy arrays to ignore the differences in column names\n",
    "\n",
    "(df_true.to_numpy() == df_v1.to_numpy()).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the above issue the results don't match the ground truth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two function calls `get_result_v2`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT Products.ProductName, SUM(\"Order Details\".UnitPrice * \"Order Details\".Quantity) AS TotalRevenue FROM Products JOIN \"Order Details\" ON Products.ProductID = \"Order Details\".ProductID GROUP BY Products.ProductName ORDER BY TotalRevenue DESC;\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductName</th>\n",
       "      <th>TotalRevenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C么te de Blaye</td>\n",
       "      <td>53274482.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Th眉ringer Rostbratwurst</td>\n",
       "      <td>24630836.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mishi Kobe Niku</td>\n",
       "      <td>19424638.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sir Rodney's Marmalade</td>\n",
       "      <td>16654879.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carnarvon Tigers</td>\n",
       "      <td>12607487.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ProductName  TotalRevenue\n",
       "0            C么te de Blaye   53274482.70\n",
       "1  Th眉ringer Rostbratwurst   24630836.96\n",
       "2          Mishi Kobe Niku   19424638.00\n",
       "3   Sir Rodney's Marmalade   16654879.80\n",
       "4         Carnarvon Tigers   12607487.50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query_v2, df_v2 = get_result_v2(question)\n",
    "print(sql_query_v2)\n",
    "df_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the dataframes are the same\n",
    "\n",
    "# We convert the dataframes to numpy arrays to ignore the differences in column names\n",
    "\n",
    "(df_true.to_numpy() == df_v2.to_numpy()).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the results match the ground truth. That, however, doesn't mean that two function calls are always better than one function call! Let's run a couple more simpler queries to compare the two approaches. Then we'll do an evaluation on a set of hand-curated questions in [`eval_questions.csv`](eval_questions.csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A couple more test queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "How many orders were shipped to Brazil?\n",
    "\"\"\"\n",
    "_, df_1 = get_result_v1(question)\n",
    "_, df_2 = get_result_v2(question)\n",
    "\n",
    "(df_1.to_numpy() == df_2.to_numpy()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "How many customers ordered more than 20 units of products?\n",
    "\"\"\"\n",
    "_, df_1 = get_result_v1(question)\n",
    "_, df_2 = get_result_v2(question)\n",
    "\n",
    "(df_1.to_numpy() == df_2.to_numpy()).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both approaches are consistent with each other and the ground truth (not shown here) for these simple queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on a hand-curated list of questions in [`eval_questions.csv`](eval_questions.csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a CSV file with 19 questions with their expected SQL queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Create a report that shows the CategoryName an...</td>\n",
       "      <td>SELECT CategoryName, Description FROM Categori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Create a report that show the ContactName, Com...</td>\n",
       "      <td>SELECT ContactName, CompanyName, ContactTitle,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Create a report that shows the capitalized Fir...</td>\n",
       "      <td>SELECT \\nUPPER(FirstName) AS [First Name], \\nU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Create a report that shows the top 10 OrderID,...</td>\n",
       "      <td>SELECT OrderID, OrderDate, ShippedDate, Custom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Create a report that shows the CustomerID in l...</td>\n",
       "      <td>SELECT LOWER(CustomerID) AS ID FROM Customers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Create a report that shows the CategoryName an...   \n",
       "1  Create a report that show the ContactName, Com...   \n",
       "2  Create a report that shows the capitalized Fir...   \n",
       "3  Create a report that shows the top 10 OrderID,...   \n",
       "4  Create a report that shows the CustomerID in l...   \n",
       "\n",
       "                                              Answer  \n",
       "0  SELECT CategoryName, Description FROM Categori...  \n",
       "1  SELECT ContactName, CompanyName, ContactTitle,...  \n",
       "2  SELECT \\nUPPER(FirstName) AS [First Name], \\nU...  \n",
       "3  SELECT OrderID, OrderDate, ShippedDate, Custom...  \n",
       "4      SELECT LOWER(CustomerID) AS ID FROM Customers  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_csv(\"eval_questions.csv\")\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the one function call approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct responses: 19/19\n"
     ]
    }
   ],
   "source": [
    "get_result = get_result_v1\n",
    "\n",
    "n_correct = 0\n",
    "for index, row in eval_df.iterrows():\n",
    "    _, query = row['Question'], row['Answer']\n",
    "    # get the true answer based on the SQL query from the eval dataset\n",
    "    df_true = read_data(query)\n",
    "    try:\n",
    "        _, df_llm = get_result(question)\n",
    "        (df_true.to_numpy() == df_llm.to_numpy()).all()\n",
    "        n_correct += 1\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "print(f\"Number of correct responses: {n_correct}/{len(eval_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the two function call approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct responses: 18/19\n"
     ]
    }
   ],
   "source": [
    "get_result = get_result_v2\n",
    "\n",
    "n_correct = 0\n",
    "for index, row in eval_df.iterrows():\n",
    "    _, query = row['Question'], row['Answer']\n",
    "    # get the true answer based on the SQL query from the eval dataset\n",
    "    df_true = read_data(query)\n",
    "    try:\n",
    "        _, df_llm = get_result(question)\n",
    "        (df_true.to_numpy() == df_llm.to_numpy()).all()\n",
    "        n_correct += 1\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "print(f\"Number of correct responses: {n_correct}/{len(eval_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "- Since the dataset is small, it's hard to say which approach provides more accurate results.\n",
    "- Interestingly, the two function call approach seems takes ~40% more time than the one function call approach (33s vs 23s).\n",
    "- The two function call approach is more flexible. In this approach, if the users questions aren't about the database, then the LLM would likely deterimine not to call the `get_schema` function. Conversly, in the one function call approach, the schema is always present in the system prompt regardless of the user's question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
